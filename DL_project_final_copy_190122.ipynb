{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_project_final_copy_190122.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/etgins/weapon_detection_with_transfer_learning/blob/main/DL_project_final_copy_190122.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !git clone https://github.com/ultralytics/yolov5"
      ],
      "metadata": {
        "id": "brET930gxZ_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yH_7jhEHHrVA",
        "outputId": "dc4e8234-4d62-4a17-f3cb-9a3dbef0e677"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/Deep_Learning\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageDraw\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "import shutil\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import time\n",
        "import copy\n",
        "import cv2\n",
        "\n",
        "\n",
        "\n",
        "from IPython.display import Image  # for displaying images\n",
        " \n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from xml.dom import minidom\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# %matplotlib notebook\n",
        "%matplotlib inline\n",
        "\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "seed = 212\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "from google.colab import drive\n",
        "drive._mount('/content/drive')\n",
        "%cd '/content/drive/MyDrive/Deep_Learning'\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset helper functions\n",
        "extract data from xml, convert to YOLOv5 format\n"
      ],
      "metadata": {
        "id": "T9GZ9A5XgJYF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to get the data from XML Annotation\n",
        "\n",
        "def extract_info_from_xml(xml_file):\n",
        "    root = ET.parse(xml_file).getroot()\n",
        "    \n",
        "    # Initialise the info dict \n",
        "    info_dict = {}\n",
        "    info_dict['bboxes'] = []\n",
        "\n",
        "    # Parse the XML Tree\n",
        "    for elem in root:\n",
        "        # Get the file name \n",
        "        if elem.tag == \"filename\":\n",
        "            info_dict['filename'] = elem.text\n",
        "            \n",
        "        # Get the image size\n",
        "        elif elem.tag == \"size\":\n",
        "            image_size = []\n",
        "            for subelem in elem:\n",
        "                image_size.append(int(subelem.text))\n",
        "            \n",
        "            info_dict['image_size'] = tuple(image_size)\n",
        "        \n",
        "        # Get details of the bounding box \n",
        "        elif elem.tag == \"object\":\n",
        "            bbox = {}\n",
        "            for subelem in elem:\n",
        "                if subelem.tag == \"name\":\n",
        "                    bbox[\"class\"] = subelem.text\n",
        "                    \n",
        "                elif subelem.tag == \"bndbox\":\n",
        "                    for subsubelem in subelem:\n",
        "                        bbox[subsubelem.tag] = int(subsubelem.text)            \n",
        "            info_dict['bboxes'].append(bbox)\n",
        "    \n",
        "    return info_dict"
      ],
      "metadata": {
        "id": "6j9pNu48PBO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# MANUAL EXTRACTION OF INFO FROM XML\n",
        "#-----------------------------------\n",
        "# tree = ET.parse('/content/drive/MyDrive/Colab Notebooks/046211_Deep_Learning/DL_project/data/Knife_detection/xmls/armas (1).xml')\n",
        "# root = tree.getroot()\n",
        "## name:\n",
        "# print(root[6][0].text)\n",
        "## coordinates: xmin\n",
        "# print(root[6][4][0].text)\n",
        "# ymin - [6][4][1]\n",
        "# xmax - [6][4][2]\n",
        "# yman - [6][4][3]\n",
        "# for obj in root.iter('object'):\n",
        "#   print(obj[0].text)\n",
        "#   print(obj[4][0].text)\n",
        "#   print(obj[4][1].text)\n",
        "#   print(obj[4][2].text)\n",
        "#   print(obj[4][3].text)\n",
        "#-----------------------------------\n",
        "# MANUAL EXTRACTION OF INFO FROM XML\n",
        "\n",
        "\n",
        "\n",
        "# USING THE ABOVE FUNCTION\n",
        "#-------------------------\n",
        "# example = extract_info_from_xml('/content/drive/MyDrive/Colab Notebooks/046211_Deep_Learning/DL_project/data/Knife_detection/xmls/armas (1).xml')\n",
        "# print(example)"
      ],
      "metadata": {
        "id": "YUJRQYfROLHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary that maps class names to IDs\n",
        "class_name_to_id_mapping = {\"pistol\": 0,\n",
        "                           \"knife\": 1}\n",
        "\n",
        "# Convert the info dict to the required yolo format and write it to disk\n",
        "def convert_to_yolov5(info_dict):\n",
        "    print_buffer = []\n",
        "    \n",
        "    # For each bounding box\n",
        "    for b in info_dict[\"bboxes\"]:\n",
        "        try:\n",
        "            class_id = class_name_to_id_mapping[b[\"class\"]]\n",
        "        except KeyError:\n",
        "            print(\"Invalid Class. Must be one from \", class_name_to_id_mapping.keys())\n",
        "        \n",
        "        # Transform the bbox co-ordinates as per the format required by YOLO v5\n",
        "        b_center_x = (b[\"xmin\"] + b[\"xmax\"]) / 2 \n",
        "        b_center_y = (b[\"ymin\"] + b[\"ymax\"]) / 2\n",
        "        b_width    = (b[\"xmax\"] - b[\"xmin\"])\n",
        "        b_height   = (b[\"ymax\"] - b[\"ymin\"])\n",
        "        \n",
        "        # Normalise the co-ordinates by the dimensions of the image\n",
        "        image_w, image_h, image_c = info_dict[\"image_size\"]  \n",
        "        b_center_x /= image_w \n",
        "        b_center_y /= image_h \n",
        "        b_width    /= image_w \n",
        "        b_height   /= image_h \n",
        "        \n",
        "        #Write the bbox details to the file \n",
        "        print_buffer.append(\"{} {:.3f} {:.3f} {:.3f} {:.3f}\".format(class_id, b_center_x, b_center_y, b_width, b_height))\n",
        "        \n",
        "    # Name of the file which we have to save \n",
        "    save_file_name = os.path.join(\"annotations2\", info_dict[\"filename\"].replace(\"JPG\", \"txt\"))\n",
        "    \n",
        "    # Save the annotation to disk\n",
        "    print(\"\\n\".join(print_buffer), file= open(save_file_name, \"w\"))\n"
      ],
      "metadata": {
        "id": "zCRqUCeDQUqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert all annotations with a loop - run once to create annotations\n",
        "\n",
        "# # Get the annotations\n",
        "# annotations = [os.path.join('annotations', x) for x in os.listdir('./data/Knife_detection/annotations') if x[-3:] == \"xml\"]\n",
        "# # annotations = [os.path.join(x) for x in os.listdir('./data/Pistol detection/xmls') if x[-3:] == \"xml\"]\n",
        "# annotations.sort()\n",
        "# print(annotations)\n",
        "\n",
        "# print(annotations)\n",
        "# # Convert and save the annotations\n",
        "\n",
        "# for ann in tqdm(annotations):\n",
        "#     print(ann)\n",
        "#     info_dict = extract_info_from_xml(os.path.join('./data/Knife_detection', ann))\n",
        "#     convert_to_yolov5(info_dict)\n",
        "# annotations = [os.path.join('annotations', x) for x in os.listdir('annotations') if x[-3:] == \"txt\"]\n",
        "# print(annotations)"
      ],
      "metadata": {
        "id": "Fav6hZgvgBN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# THIS IS TEMP AND ONE-TIME\n",
        "# ##########################\n",
        "\n",
        "# def add_numbers(filename):\n",
        "#     with open(filename, 'r') as readfile:\n",
        "#         data = readfile.readlines()\n",
        "#     with open(filename, 'w') as writefile:\n",
        "#         for i, line in enumerate(data):\n",
        "#             writefile.write('%s %s' % (line, '.txt'))\n",
        "\n",
        "# filename = './annotations/armas (1)'\n",
        "# add_numbers(filename)\n",
        "\n",
        "# for path, _, filenames in os.walk(folder):\n",
        "#     for filename in filenames:\n",
        "#         add_numbers(os.path.join(path, filename))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### USE THIS TO ADD .txt TO ANNOTATIONS (IF NEEDED):\n",
        "#############\n",
        "# from pathlib import Path\n",
        "# for file in range(3,3001): \n",
        "#   p = Path('./annotations/armas (' + str(file) + ')')\n",
        "#   p.rename(p.with_suffix('.txt'))\n",
        "#############\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# THIS IS TEMP AND ONE-TIME\n",
        "# ##########################"
      ],
      "metadata": {
        "id": "jVcXT9O5fJsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "\n",
        "# for first time:\n",
        "# ---------------\n",
        "# annotations = os.listdir('annotations')\n",
        "# annotations.sort()\n",
        "# # print('annotations: ', annotations)\n",
        "# images = os.listdir('images')\n",
        "# images.sort()\n",
        "# # print('images: ', images)\n",
        "# ---------------\n",
        "\n",
        "# for second time and on:\n",
        "# ---------------\n",
        "train_annotations = os.listdir('datasets/coco/labels/train')\n",
        "train_annotations.sort()\n",
        "train_images = os.listdir('datasets/coco/images/train')\n",
        "train_images.sort()\n",
        "# ---------------\n",
        "\n",
        "\n",
        "class_id_to_name_mapping = dict(zip(class_name_to_id_mapping.values(), class_name_to_id_mapping.keys()))\n",
        "\n",
        "def plot_bounding_box(image, annotation_list):\n",
        "    annotations = np.array(annotation_list)\n",
        "    w, h = image.size\n",
        "    \n",
        "    plotted_image = ImageDraw.Draw(image)\n",
        "\n",
        "    transformed_annotations = np.copy(annotations)\n",
        "    transformed_annotations[:,[1,3]] = annotations[:,[1,3]] * w\n",
        "    transformed_annotations[:,[2,4]] = annotations[:,[2,4]] * h \n",
        "    \n",
        "    transformed_annotations[:,1] = transformed_annotations[:,1] - (transformed_annotations[:,3] / 2)\n",
        "    transformed_annotations[:,2] = transformed_annotations[:,2] - (transformed_annotations[:,4] / 2)\n",
        "    transformed_annotations[:,3] = transformed_annotations[:,1] + transformed_annotations[:,3]\n",
        "    transformed_annotations[:,4] = transformed_annotations[:,2] + transformed_annotations[:,4]\n",
        "    \n",
        "    for ann in transformed_annotations:\n",
        "        obj_cls, x0, y0, x1, y1 = ann\n",
        "        plotted_image.rectangle(((x0,y0), (x1,y1)), outline =\"red\", width = 4)     # fill =\"#ffff33\"\n",
        "        \n",
        "        plotted_image.text((x0, y0 - 10), class_id_to_name_mapping[(int(obj_cls))])\n",
        "    \n",
        "    plt.imshow(np.array(image))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Get any random annotation file \n",
        "annotation_file = random.choice(train_annotations)\n",
        "print('short annotation file:', annotation_file)\n",
        "annotation_file = os.path.join('datasets/coco//labels/train', annotation_file)\n",
        "# print('long annotation file:', annotation_file)\n",
        "\n",
        "with open(annotation_file, \"r\") as file:\n",
        "    annotation_list = file.read().split(\"\\n\")[:-1]\n",
        "    # print('annotation file content:', annotation_list)\n",
        "    annotation_list = [x.split(\" \") for x in annotation_list]\n",
        "    annotation_list = [[float(y) for y in x ] for x in annotation_list]\n",
        "\n",
        "#Get the corresponding image file\n",
        "image_file = annotation_file.replace(\"labels\", \"images\").replace(\"txt\", \"jpg\")\n",
        "print('image file:', image_file)\n",
        "# assert os.path.exists(image_file)\n",
        "\n",
        "#Load the image\n",
        "image = Image.open(image_file)\n",
        "# image.show()\n",
        "#Plot the Bounding Box\n",
        "plot_bounding_box(image, annotation_list)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ji_kKbDmYy34",
        "outputId": "eebad121-bb5b-4864-82f7-264bb87c1092"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-77b6404074d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# for second time and on:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# ---------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtrain_annotations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'datasets/coco/labels/train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mtrain_annotations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mtrain_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'datasets/coco/images/train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data split and re-organize"
      ],
      "metadata": {
        "id": "Sg24p8mFlnnJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read images and annotations\n",
        "\n",
        "# images = [x for x in os.listdir('images') if x[-3:] == \"jpg\"]\n",
        "# annotations = [x for x in os.listdir('annotations') if x[-3:] == \"txt\"]\n",
        "\n",
        "\n",
        "# option a: Split the dataset into train-valid-test splits - for first split (all in the same directory)\n",
        "# --------------------------------------------------------------------------------------------\n",
        "# --------------------------------------------------------------------------------------------\n",
        "# images = [os.path.join('images', x) for x in os.listdir('images') if x[-3:] == 'jpg']\n",
        "# annotations = [os.path.join('annotations', x) for x in os.listdir('annotations') if x[-3:] == \"txt\"]\n",
        "\n",
        "# images.sort()\n",
        "# annotations.sort()\n",
        "\n",
        "# # print(images)\n",
        "# # print(annotations)\n",
        "\n",
        "# print(len(images))\n",
        "# print(len(annotations))\n",
        "\n",
        "# train_images, test_images, train_annotations, test_annotations = train_test_split(images, annotations, test_size = 0.2, random_state = 1)\n",
        "# val_images, test_images, val_annotations, test_annotations = train_test_split(val_images, val_annotations, test_size = 0.5, random_state = 1)\n",
        "\n",
        "# --------------------------------------------------------------------------------------------\n",
        "# --------------------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# option b: Split the dataset - if already split into separate directories:\n",
        "# --------------------------------------------------------------------------------------------\n",
        "# --------------------------------------------------------------------------------------------\n",
        "\n",
        "train_images = [os.path.join('datasets/coco/images/train', x) for x in os.listdir('datasets/coco/images/train')  if x[-3:] == 'jpg']\n",
        "test_images = [os.path.join('datasets/coco/images/test', x) for x in os.listdir('datasets/coco/images/test')  if x[-3:] == 'jpg']\n",
        "train_annotations = [os.path.join('datasets/coco/labels/train', x) for x in os.listdir('datasets/coco/labels/train') if x[-3:] == \"txt\"]\n",
        "test_annotations = [os.path.join('datasets/coco/labels/test', x) for x in os.listdir('datasets/coco/labels/test')if x[-3:] == \"txt\"]\n",
        "\n",
        "train_images.sort()\n",
        "test_annotations.sort()\n",
        "train_annotations.sort()\n",
        "test_images.sort()\n",
        "\n",
        "# print(len(train_images), 'train images: ', train_images)\n",
        "# print(len(train_annotations), 'train_annotations: ', train_annotations)\n",
        "# print(len(test_images),'test images: ', test_images)\n",
        "# print(len(test_annotations), 'test_annotations: ', test_annotations)\n",
        "\n",
        "\n",
        "# --------------------------------------------------------------------------------------------\n",
        "# --------------------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "PVc-Rld5lmnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !mkdir images/train images/test annotations/train annotations/test"
      ],
      "metadata": {
        "id": "Lq8to85bmQmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Utility function to move images \n",
        "def move_files_to_folder(list_of_files, destination_folder):\n",
        "    for f in list_of_files:\n",
        "        print(f)\n",
        "        try:\n",
        "            shutil.move(f, destination_folder)\n",
        "        except:\n",
        "            print(f, 'failed')\n",
        "            assert False\n"
      ],
      "metadata": {
        "id": "Rbi5sHUknzt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Move the splits into their folders\n",
        "\n",
        "# move_files_to_folder(train_images, 'images/train')\n",
        "# move_files_to_folder(train_annotations, 'annotations/train/')\n",
        "# move_files_to_folder(test_images, 'images/test/')\n",
        "# move_files_to_folder(test_annotations, 'annotations/test/')"
      ],
      "metadata": {
        "id": "cgzKLDDe7pBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model\n",
        "importing, training and detecting"
      ],
      "metadata": {
        "id": "hUOeWc10ePzO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/drive/MyDrive/Deep_Learning/yolov5'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBwPUJyTL8Nv",
        "outputId": "5cf2f871-0d5a-450c-fedb-a45c8ad5afac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Deep_Learning/yolov5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9gTzousL3R2",
        "outputId": "e9042a9b-6fb1-4193-ba79-5ada462dc313"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 10555, done.\u001b[K\n",
            "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 10555 (delta 3), reused 6 (delta 3), pack-reused 10547\u001b[K\n",
            "Receiving objects: 100% (10555/10555), 10.75 MiB | 9.26 MiB/s, done.\n",
            "Resolving deltas: 100% (7288/7288), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!which pip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjpTnOXsNOXi",
        "outputId": "78f59ca2-c1da-410e-da95-cdca5096c7f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/bin/pip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYedbYVVNpnt",
        "outputId": "4173d01e-97a8-4171-a9fa-aef69a40c2fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Deep_Learning/yolov5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZDDWWh1Nfq3",
        "outputId": "056c8712-2057-42b9-ad44-b9755ee48a79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (1.19.5)\n",
            "Requirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (4.1.2.30)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (7.1.2)\n",
            "Collecting PyYAML>=5.3.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (2.23.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (1.4.1)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (0.11.1+cu111)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (4.62.3)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 16)) (2.7.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 20)) (1.1.5)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 21)) (0.11.2)\n",
            "Collecting thop\n",
            "  Downloading thop-0.0.31.post2005241907-py3-none-any.whl (8.7 kB)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (3.0.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (0.11.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2.10)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7.0->-r requirements.txt (line 11)) (3.10.0.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.6.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.12.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.37.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (3.17.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.8.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (57.4.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.4.6)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 20)) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.15.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 16)) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 16)) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 16)) (4.10.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 16)) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 16)) (3.1.1)\n",
            "Installing collected packages: thop, PyYAML\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed PyYAML-6.0 thop-0.0.31.post2005241907\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bw34PJVruE38",
        "outputId": "ade8be3d-1561-41b5-c263-1cf4b5295124"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --img 640 --cfg yolov5s.yaml --hyp hyp.scratch.yaml --batch 32 --epochs 100 --data Weapons.yaml --weights yolov5s.pt --workers 24 --name yolo_weapons_det"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJ7NeC29YPBi",
        "outputId": "cde4f67b-a181-46ee-e3ed-b6a6745033cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=yolov5s.yaml, data=Weapons.yaml, hyp=hyp.scratch.yaml, epochs=100, batch_size=32, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=24, project=runs/train, name=yolo_weapons_det, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0m⚠️ YOLOv5 is out of date by 5 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
            "YOLOv5 🚀 2022-1-15 torch 1.10.0+cu111 CUDA:0 (Tesla K80, 11441MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 🚀 runs (RECOMMENDED)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     18879  models.yolo.Detect                      [2, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model Summary: 270 layers, 7025023 parameters, 7025023 gradients, 15.9 GFLOPs\n",
            "\n",
            "Transferred 342/349 items from yolov5s.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight, 60 weight (no decay), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '../labels/train.cache' images and labels... 4061 found, 0 missing, 0 empty, 1 corrupted: 100% 4061/4061 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: ../images/train/armas (2815).jpg: ignoring corrupt image/label: non-normalized or out of bounds coordinates [      2.873       1.619]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '../labels/val.cache' images and labels... 1016 found, 0 missing, 0 empty, 0 corrupted: 100% 1016/1016 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING: ../images/val/armas (1221).jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING: ../images/val/armas (1717).jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING: ../images/val/armas (2843).jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING: ../images/val/armas (2903).jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING: ../images/val/armas (612).jpg: corrupt JPEG restored and saved\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING: ../images/val/knife_71.jpg: corrupt JPEG restored and saved\n",
            "Plotting labels to runs/train/yolo_weapons_det5/labels.jpg... \n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m3.89 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/yolo_weapons_det5\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      0/99     6.23G   0.08322   0.02626    0.0211        66       640: 100% 127/127 [06:03<00:00,  2.86s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 16/16 [00:27<00:00,  1.72s/it]\n",
            "                 all       1016       1121      0.456      0.561      0.437      0.158\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      1/99     10.4G   0.05529   0.02115  0.006912        66       640: 100% 127/127 [05:58<00:00,  2.82s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 16/16 [00:28<00:00,  1.79s/it]\n",
            "                 all       1016       1121      0.564      0.664      0.611      0.253\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      2/99     10.4G   0.04927   0.01833   0.00409        71       640: 100% 127/127 [05:59<00:00,  2.83s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 16/16 [00:27<00:00,  1.69s/it]\n",
            "                 all       1016       1121      0.738      0.684      0.733      0.365\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      3/99     10.4G   0.04572   0.01735  0.003529        69       640: 100% 127/127 [05:59<00:00,  2.83s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 16/16 [00:27<00:00,  1.75s/it]\n",
            "                 all       1016       1121      0.773      0.735      0.809      0.329\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      4/99     10.4G    0.0474   0.01682  0.004026        67       640: 100% 127/127 [05:54<00:00,  2.79s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 16/16 [00:27<00:00,  1.71s/it]\n",
            "                 all       1016       1121      0.805      0.742      0.801      0.336\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      5/99     10.4G   0.04327   0.01674  0.004217        83       640: 100% 127/127 [05:54<00:00,  2.79s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 16/16 [00:26<00:00,  1.66s/it]\n",
            "                 all       1016       1121      0.658      0.573      0.676      0.327\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      6/99     10.4G   0.04329   0.01699  0.004492        76       640: 100% 127/127 [05:52<00:00,  2.78s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 16/16 [00:26<00:00,  1.67s/it]\n",
            "                 all       1016       1121      0.751      0.662      0.739      0.376\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      7/99     10.4G   0.04305   0.01786  0.005035        68       640: 100% 127/127 [05:57<00:00,  2.82s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 16/16 [00:26<00:00,  1.69s/it]\n",
            "                 all       1016       1121      0.653      0.598      0.632      0.295\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      8/99     10.4G   0.04324   0.01816  0.005266        72       640: 100% 127/127 [05:56<00:00,  2.80s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 16/16 [00:26<00:00,  1.66s/it]\n",
            "                 all       1016       1121      0.672       0.55      0.615      0.297\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      9/99     10.4G   0.04198   0.01744  0.004305        79       640: 100% 127/127 [05:53<00:00,  2.78s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 16/16 [00:27<00:00,  1.70s/it]\n",
            "                 all       1016       1121      0.793      0.659      0.755      0.392\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     10/99     10.4G   0.04034   0.01723  0.003676        79       640: 100% 127/127 [05:56<00:00,  2.81s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 16/16 [00:27<00:00,  1.73s/it]\n",
            "                 all       1016       1121      0.783      0.721      0.789      0.424\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     11/99     10.4G    0.0383   0.01678  0.003513        57       640: 100% 127/127 [05:59<00:00,  2.83s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 16/16 [00:26<00:00,  1.64s/it]\n",
            "                 all       1016       1121      0.822      0.752      0.823      0.454\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     12/99     10.4G   0.03751   0.01625   0.00309        64       640: 100% 127/127 [05:56<00:00,  2.81s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 16/16 [00:26<00:00,  1.66s/it]\n",
            "                 all       1016       1121      0.871      0.745      0.848       0.49\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     13/99     10.4G   0.03666   0.01567  0.002801        70       640: 100% 127/127 [05:59<00:00,  2.83s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 16/16 [00:26<00:00,  1.63s/it]\n",
            "                 all       1016       1121      0.847      0.786      0.862        0.5\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     14/99     10.4G   0.03592   0.01594  0.002609        71       640: 100% 127/127 [05:58<00:00,  2.82s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 16/16 [00:27<00:00,  1.71s/it]\n",
            "                 all       1016       1121      0.903      0.739      0.858      0.508\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     15/99     10.4G   0.03489   0.01533  0.002141        75       640: 100% 127/127 [05:59<00:00,  2.83s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 16/16 [00:27<00:00,  1.74s/it]\n",
            "                 all       1016       1121      0.842      0.817      0.885      0.543\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     16/99     10.4G   0.03419   0.01525  0.002299        61       640: 100% 127/127 [05:55<00:00,  2.80s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 16/16 [00:26<00:00,  1.67s/it]\n",
            "                 all       1016       1121       0.86      0.788      0.866      0.495\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     17/99     10.4G   0.03417   0.01536  0.002556        65       640: 100% 127/127 [05:55<00:00,  2.80s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 16/16 [00:26<00:00,  1.65s/it]\n",
            "                 all       1016       1121      0.875      0.818      0.893      0.549\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     18/99     10.4G   0.03346   0.01486  0.002222        63       640: 100% 127/127 [05:59<00:00,  2.83s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 16/16 [00:26<00:00,  1.64s/it]\n",
            "                 all       1016       1121      0.885      0.801      0.893      0.563\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     19/99     10.4G   0.03289   0.01476  0.002128        71       640: 100% 127/127 [05:57<00:00,  2.82s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 16/16 [00:26<00:00,  1.68s/it]\n",
            "                 all       1016       1121      0.878      0.815      0.881      0.541\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     20/99     10.4G   0.03256   0.01475   0.00213        86       640: 100% 127/127 [05:54<00:00,  2.79s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 16/16 [00:27<00:00,  1.72s/it]\n",
            "                 all       1016       1121      0.896      0.831      0.899      0.547\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     21/99     10.4G   0.03222   0.01472  0.001815        68       640: 100% 127/127 [05:54<00:00,  2.79s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 16/16 [00:26<00:00,  1.66s/it]\n",
            "                 all       1016       1121       0.92      0.808      0.903      0.582\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     22/99     10.4G   0.03184   0.01435    0.0019        69       640: 100% 127/127 [05:59<00:00,  2.83s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 16/16 [00:26<00:00,  1.65s/it]\n",
            "                 all       1016       1121       0.87      0.838      0.904      0.563\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     23/99     10.4G   0.03134   0.01439  0.001632        61       640: 100% 127/127 [05:59<00:00,  2.83s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 16/16 [00:27<00:00,  1.72s/it]\n",
            "                 all       1016       1121      0.913      0.825      0.905      0.584\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     24/99     10.4G   0.03125   0.01437  0.001836        70       640: 100% 127/127 [06:00<00:00,  2.84s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 16/16 [00:27<00:00,  1.69s/it]\n",
            "                 all       1016       1121      0.875      0.825      0.899      0.546\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     25/99     10.4G   0.03054   0.01408  0.001956        63       640: 100% 127/127 [06:07<00:00,  2.89s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 16/16 [00:27<00:00,  1.72s/it]\n",
            "                 all       1016       1121      0.887      0.864      0.913      0.592\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     26/99     10.4G   0.03048   0.01381  0.001943        65       640: 100% 127/127 [06:04<00:00,  2.87s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 16/16 [00:26<00:00,  1.68s/it]\n",
            "                 all       1016       1121      0.849      0.872      0.905      0.574\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     27/99     10.4G   0.03018   0.01386  0.001554        62       640: 100% 127/127 [06:02<00:00,  2.85s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 16/16 [00:27<00:00,  1.70s/it]\n",
            "                 all       1016       1121      0.934      0.846      0.928      0.592\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     28/99     10.4G   0.03004   0.01374  0.001492        66       640: 100% 127/127 [06:04<00:00,  2.87s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 16/16 [00:26<00:00,  1.67s/it]\n",
            "                 all       1016       1121      0.903      0.839      0.913      0.582\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     29/99     10.4G   0.02903   0.01332  0.001687        71       640: 100% 127/127 [05:59<00:00,  2.83s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 16/16 [00:26<00:00,  1.69s/it]\n",
            "                 all       1016       1121      0.912      0.866       0.93      0.595\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     30/99     10.4G   0.02927   0.01327  0.001346        64       640: 100% 127/127 [05:57<00:00,  2.82s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 16/16 [00:26<00:00,  1.65s/it]\n",
            "                 all       1016       1121      0.903      0.843      0.919      0.585\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     31/99     10.4G   0.02911   0.01331  0.001284        87       640: 100% 127/127 [05:57<00:00,  2.82s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 16/16 [00:27<00:00,  1.71s/it]\n",
            "                 all       1016       1121      0.914      0.865      0.936      0.615\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     32/99     10.4G   0.02866   0.01306  0.001355        72       640: 100% 127/127 [05:58<00:00,  2.82s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 16/16 [00:27<00:00,  1.72s/it]\n",
            "                 all       1016       1121      0.894      0.869      0.926      0.603\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     33/99     10.4G   0.02837   0.01294  0.001368        69       640: 100% 127/127 [05:56<00:00,  2.80s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 16/16 [00:27<00:00,  1.71s/it]\n",
            "                 all       1016       1121      0.904      0.869      0.926      0.603\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     34/99     10.4G   0.02796   0.01298  0.001581        69       640: 100% 127/127 [05:57<00:00,  2.82s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 16/16 [00:26<00:00,  1.67s/it]\n",
            "                 all       1016       1121      0.897      0.903      0.941      0.623\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     35/99     10.4G   0.02802   0.01299   0.00132        75       640: 100% 127/127 [05:53<00:00,  2.79s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 16/16 [00:28<00:00,  1.76s/it]\n",
            "                 all       1016       1121       0.92      0.849      0.923      0.591\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     36/99     10.4G   0.02776   0.01286  0.001268        76       640: 100% 127/127 [06:01<00:00,  2.85s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 16/16 [00:25<00:00,  1.61s/it]\n",
            "                 all       1016       1121        0.9      0.869      0.933      0.623\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     37/99     10.4G   0.02713   0.01273  0.001223        78       640: 100% 127/127 [05:58<00:00,  2.82s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 16/16 [00:28<00:00,  1.78s/it]\n",
            "                 all       1016       1121      0.914      0.891      0.943      0.627\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     38/99     10.4G   0.02713   0.01261  0.001306        69       640: 100% 127/127 [06:01<00:00,  2.85s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 16/16 [00:27<00:00,  1.74s/it]\n",
            "                 all       1016       1121      0.919      0.872      0.932      0.619\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     39/99     10.4G   0.02694    0.0125  0.001234        61       640: 100% 127/127 [06:02<00:00,  2.86s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 16/16 [00:26<00:00,  1.67s/it]\n",
            "                 all       1016       1121      0.919      0.872      0.932      0.626\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     40/99     10.4G    0.0269   0.01276  0.001306        64       640: 100% 127/127 [06:03<00:00,  2.86s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 16/16 [00:26<00:00,  1.65s/it]\n",
            "                 all       1016       1121      0.888      0.912      0.945      0.636\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     41/99     10.4G   0.02632   0.01237  0.001143        82       640: 100% 127/127 [05:59<00:00,  2.83s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 16/16 [00:27<00:00,  1.75s/it]\n",
            "                 all       1016       1121      0.922      0.891      0.944      0.636\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     42/99     10.4G   0.02607   0.01221 0.0009112        83       640: 100% 127/127 [06:00<00:00,  2.84s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 16/16 [00:26<00:00,  1.68s/it]\n",
            "                 all       1016       1121      0.917      0.893      0.949      0.636\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     43/99     10.4G   0.02568   0.01193  0.000897        78       640: 100% 127/127 [05:59<00:00,  2.83s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 16/16 [00:27<00:00,  1.71s/it]\n",
            "                 all       1016       1121      0.923      0.895      0.952       0.64\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     44/99     10.4G   0.02594   0.01207 0.0009906        75       640: 100% 127/127 [06:01<00:00,  2.85s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 16/16 [00:26<00:00,  1.66s/it]\n",
            "                 all       1016       1121       0.92      0.893      0.943      0.636\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     45/99     10.4G   0.02558   0.01222 0.0008523        54       640: 100% 127/127 [06:01<00:00,  2.85s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 16/16 [00:27<00:00,  1.75s/it]\n",
            "                 all       1016       1121      0.913       0.92      0.951      0.641\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     46/99     10.4G    0.0256   0.01191  0.001203        74       640: 100% 127/127 [06:01<00:00,  2.85s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 16/16 [00:26<00:00,  1.68s/it]\n",
            "                 all       1016       1121       0.93       0.88      0.941      0.638\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     47/99     10.4G   0.02512   0.01187  0.000976        73       640: 100% 127/127 [06:02<00:00,  2.85s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 16/16 [00:27<00:00,  1.72s/it]\n",
            "                 all       1016       1121      0.929        0.9      0.949      0.646\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     48/99     10.4G   0.02477   0.01202 0.0008336        72       640: 100% 127/127 [06:04<00:00,  2.87s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 16/16 [00:28<00:00,  1.75s/it]\n",
            "                 all       1016       1121      0.929      0.896       0.95       0.65\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     49/99     10.4G   0.02458   0.01163 0.0008193        85       640: 100% 127/127 [06:03<00:00,  2.86s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 16/16 [00:26<00:00,  1.64s/it]\n",
            "                 all       1016       1121      0.934      0.888      0.949      0.654\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     50/99     10.4G   0.02425   0.01161 0.0008452        68       640: 100% 127/127 [06:00<00:00,  2.84s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 16/16 [00:28<00:00,  1.76s/it]\n",
            "                 all       1016       1121      0.933      0.891      0.946      0.657\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     51/99     10.4G   0.02415   0.01148 0.0009036        85       640: 100% 127/127 [06:01<00:00,  2.85s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 16/16 [00:26<00:00,  1.66s/it]\n",
            "                 all       1016       1121      0.919      0.897      0.944      0.649\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     52/99     10.4G   0.02403   0.01125 0.0008742        76       640: 100% 127/127 [06:00<00:00,  2.84s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 16/16 [00:26<00:00,  1.68s/it]\n",
            "                 all       1016       1121      0.921      0.906      0.951      0.655\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     53/99     10.4G   0.02374   0.01113 0.0008491        72       640: 100% 127/127 [05:55<00:00,  2.80s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 16/16 [00:28<00:00,  1.76s/it]\n",
            "                 all       1016       1121      0.946      0.905      0.957      0.662\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     54/99     10.4G   0.02359   0.01113 0.0007529        66       640: 100% 127/127 [05:54<00:00,  2.79s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 16/16 [00:28<00:00,  1.76s/it]\n",
            "                 all       1016       1121      0.926      0.914      0.956      0.663\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     55/99     10.4G   0.02316   0.01099 0.0007341        51       640: 100% 127/127 [05:57<00:00,  2.82s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 16/16 [00:25<00:00,  1.62s/it]\n",
            "                 all       1016       1121      0.946        0.9      0.954      0.651\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     56/99     10.4G   0.02306   0.01107 0.0008409        79       640: 100% 127/127 [05:58<00:00,  2.82s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 16/16 [00:26<00:00,  1.65s/it]\n",
            "                 all       1016       1121      0.933      0.908      0.953      0.661\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     57/99     10.4G    0.0229   0.01101 0.0008406        87       640: 100% 127/127 [05:54<00:00,  2.79s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 16/16 [00:27<00:00,  1.70s/it]\n",
            "                 all       1016       1121      0.935      0.898      0.951      0.657\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     58/99     10.4G   0.02285   0.01102 0.0007675        83       640:  99% 126/127 [05:56<00:02,  2.73s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --source ../images/test/ --weights runs/train/yolo_weapons_det5/weights/best.pt --conf 0.25 --name yolo_weapons_det"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrVPgiNVAZ5l",
        "outputId": "c8ebbf62-47e3-4288-91ee-69616aeb9002"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['runs/train/yolo_weapons_det5/weights/best.pt'], source=../images/alon/, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=yolo_weapons_det_alon, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
            "YOLOv5 🚀 2022-1-15 torch 1.10.0+cu111 CPU\n",
            "\n",
            "Fusing layers... \n",
            "Model Summary: 213 layers, 7015519 parameters, 0 gradients, 15.8 GFLOPs\n",
            "image 1/3 /content/drive/My Drive/Deep_Learning/images/alon/image0.jpg: 448x640 1 pistol, Done. (0.289s)\n",
            "image 2/3 /content/drive/My Drive/Deep_Learning/images/alon/image1.jpg: 384x640 1 pistol, Done. (0.244s)\n",
            "image 3/3 /content/drive/My Drive/Deep_Learning/images/alon/image2.jpg: 384x640 1 pistol, Done. (0.239s)\n",
            "Speed: 1.7ms pre-process, 257.5ms inference, 1.9ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/yolo_weapons_det_alon3\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}