{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DL_project.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMcomogDwyDsWGOAT4KHDwe"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yH_7jhEHHrVA","executionInfo":{"status":"ok","timestamp":1641544060240,"user_tz":-120,"elapsed":1925,"user":{"displayName":"itamar ginsberg","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhgNNu4rKWDIJbuQ6EjlVLGe3VMZEHSAKyW4bG5qQ=s64","userId":"14768070087940992282"}},"outputId":"9ca816be-a1fb-42cb-aa33-c66eaa3046b6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/Colab Notebooks/046211_Deep_Learning/DL_project\n"]}],"source":["# imports for the practice (you can add more if you need)\n","import os\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torchvision\n","from torchvision import transforms\n","import matplotlib.pyplot as plt\n","from PIL import Image, ImageDraw\n","from tqdm import tqdm\n","import random\n","from sklearn.model_selection import train_test_split\n","import shutil\n","\n","\n","# %matplotlib notebook\n","%matplotlib inline\n","\n","import xml.etree.ElementTree as ET\n","\n","seed = 212\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","%cd '/content/drive/MyDrive/Colab Notebooks/046211_Deep_Learning/DL_project'\n","\n"]},{"cell_type":"markdown","source":["# Sources\n","‚≠ê1. training yolo v5 on a custom dataset: https://blog.paperspace.com/train-yolov5-custom-data/\n","2. pytorch data loading tutorial: https://colab.research.google.com/github/pytorch/tutorials/blob/gh-pages/_downloads/21adbaecd47a412f8143afb1c48f05a6/data_loading_tutorial.ipynb#scrollTo=6S5I0VfvBsPq\n","3. pytorch transfer learning for CV: https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html?highlight=transfer_learning_tutorial\n"],"metadata":{"id":"l4N0OONPhYLm"}},{"cell_type":"markdown","source":["# Load model, freeze layers\n","----"],"metadata":{"id":"bviGSMX7OApg"}},{"cell_type":"code","source":["# model = torchvision.models.detection.mask_rcnn(pretrained=False, progress=True, num_classes=91, pretrained_backbone=True, trainable_backbone_layers=None, **kwargs)\n","# model = torchvision.models.googlenet(pretrained = True, progress=True)\n","# model.eval()\n","\n","# YOLO V5 model\n","model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)"],"metadata":{"id":"bbdMcC8VHtmy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641544061036,"user_tz":-120,"elapsed":799,"user":{"displayName":"itamar ginsberg","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhgNNu4rKWDIJbuQ6EjlVLGe3VMZEHSAKyW4bG5qQ=s64","userId":"14768070087940992282"}},"outputId":"d3610ceb-0e67-45b4-e8a4-f9804954e7e1"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n","YOLOv5 üöÄ 2022-1-7 torch 1.10.0+cu111 CPU\n","\n","Fusing layers... \n","Model Summary: 213 layers, 7225885 parameters, 0 gradients\n","Adding AutoShape... \n"]}]},{"cell_type":"code","source":["model.eval()\n","\n","# show model layers\n","# for k, v in model.named_parameters():\n","#     print(k)\n","\n","# Freeze \n","freeze = 23\n","freeze = [f'model.{x}.' for x in range(freeze)]  # layers to freeze \n","for k, v in model.named_parameters(): \n","    v.requires_grad = True  # train all layers \n","    if any(x in k for x in freeze): \n","        print(f'freezing {k}') \n","        v.requires_grad = False \n","    else:\n","      print(f'not freezing {k}') "],"metadata":{"id":"r7hgjgoIJmEb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641544061524,"user_tz":-120,"elapsed":491,"user":{"displayName":"itamar ginsberg","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhgNNu4rKWDIJbuQ6EjlVLGe3VMZEHSAKyW4bG5qQ=s64","userId":"14768070087940992282"}},"outputId":"27bdde0e-dfc7-41ca-c186-d12710e3b2a3"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["freezing model.model.model.0.conv.weight\n","freezing model.model.model.0.conv.bias\n","freezing model.model.model.1.conv.weight\n","freezing model.model.model.1.conv.bias\n","freezing model.model.model.2.cv1.conv.weight\n","freezing model.model.model.2.cv1.conv.bias\n","freezing model.model.model.2.cv2.conv.weight\n","freezing model.model.model.2.cv2.conv.bias\n","freezing model.model.model.2.cv3.conv.weight\n","freezing model.model.model.2.cv3.conv.bias\n","freezing model.model.model.2.m.0.cv1.conv.weight\n","freezing model.model.model.2.m.0.cv1.conv.bias\n","freezing model.model.model.2.m.0.cv2.conv.weight\n","freezing model.model.model.2.m.0.cv2.conv.bias\n","freezing model.model.model.3.conv.weight\n","freezing model.model.model.3.conv.bias\n","freezing model.model.model.4.cv1.conv.weight\n","freezing model.model.model.4.cv1.conv.bias\n","freezing model.model.model.4.cv2.conv.weight\n","freezing model.model.model.4.cv2.conv.bias\n","freezing model.model.model.4.cv3.conv.weight\n","freezing model.model.model.4.cv3.conv.bias\n","freezing model.model.model.4.m.0.cv1.conv.weight\n","freezing model.model.model.4.m.0.cv1.conv.bias\n","freezing model.model.model.4.m.0.cv2.conv.weight\n","freezing model.model.model.4.m.0.cv2.conv.bias\n","freezing model.model.model.4.m.1.cv1.conv.weight\n","freezing model.model.model.4.m.1.cv1.conv.bias\n","freezing model.model.model.4.m.1.cv2.conv.weight\n","freezing model.model.model.4.m.1.cv2.conv.bias\n","freezing model.model.model.5.conv.weight\n","freezing model.model.model.5.conv.bias\n","freezing model.model.model.6.cv1.conv.weight\n","freezing model.model.model.6.cv1.conv.bias\n","freezing model.model.model.6.cv2.conv.weight\n","freezing model.model.model.6.cv2.conv.bias\n","freezing model.model.model.6.cv3.conv.weight\n","freezing model.model.model.6.cv3.conv.bias\n","freezing model.model.model.6.m.0.cv1.conv.weight\n","freezing model.model.model.6.m.0.cv1.conv.bias\n","freezing model.model.model.6.m.0.cv2.conv.weight\n","freezing model.model.model.6.m.0.cv2.conv.bias\n","freezing model.model.model.6.m.1.cv1.conv.weight\n","freezing model.model.model.6.m.1.cv1.conv.bias\n","freezing model.model.model.6.m.1.cv2.conv.weight\n","freezing model.model.model.6.m.1.cv2.conv.bias\n","freezing model.model.model.6.m.2.cv1.conv.weight\n","freezing model.model.model.6.m.2.cv1.conv.bias\n","freezing model.model.model.6.m.2.cv2.conv.weight\n","freezing model.model.model.6.m.2.cv2.conv.bias\n","freezing model.model.model.7.conv.weight\n","freezing model.model.model.7.conv.bias\n","freezing model.model.model.8.cv1.conv.weight\n","freezing model.model.model.8.cv1.conv.bias\n","freezing model.model.model.8.cv2.conv.weight\n","freezing model.model.model.8.cv2.conv.bias\n","freezing model.model.model.8.cv3.conv.weight\n","freezing model.model.model.8.cv3.conv.bias\n","freezing model.model.model.8.m.0.cv1.conv.weight\n","freezing model.model.model.8.m.0.cv1.conv.bias\n","freezing model.model.model.8.m.0.cv2.conv.weight\n","freezing model.model.model.8.m.0.cv2.conv.bias\n","freezing model.model.model.9.cv1.conv.weight\n","freezing model.model.model.9.cv1.conv.bias\n","freezing model.model.model.9.cv2.conv.weight\n","freezing model.model.model.9.cv2.conv.bias\n","freezing model.model.model.10.conv.weight\n","freezing model.model.model.10.conv.bias\n","freezing model.model.model.13.cv1.conv.weight\n","freezing model.model.model.13.cv1.conv.bias\n","freezing model.model.model.13.cv2.conv.weight\n","freezing model.model.model.13.cv2.conv.bias\n","freezing model.model.model.13.cv3.conv.weight\n","freezing model.model.model.13.cv3.conv.bias\n","freezing model.model.model.13.m.0.cv1.conv.weight\n","freezing model.model.model.13.m.0.cv1.conv.bias\n","freezing model.model.model.13.m.0.cv2.conv.weight\n","freezing model.model.model.13.m.0.cv2.conv.bias\n","freezing model.model.model.14.conv.weight\n","freezing model.model.model.14.conv.bias\n","freezing model.model.model.17.cv1.conv.weight\n","freezing model.model.model.17.cv1.conv.bias\n","freezing model.model.model.17.cv2.conv.weight\n","freezing model.model.model.17.cv2.conv.bias\n","freezing model.model.model.17.cv3.conv.weight\n","freezing model.model.model.17.cv3.conv.bias\n","freezing model.model.model.17.m.0.cv1.conv.weight\n","freezing model.model.model.17.m.0.cv1.conv.bias\n","freezing model.model.model.17.m.0.cv2.conv.weight\n","freezing model.model.model.17.m.0.cv2.conv.bias\n","freezing model.model.model.18.conv.weight\n","freezing model.model.model.18.conv.bias\n","freezing model.model.model.20.cv1.conv.weight\n","freezing model.model.model.20.cv1.conv.bias\n","freezing model.model.model.20.cv2.conv.weight\n","freezing model.model.model.20.cv2.conv.bias\n","freezing model.model.model.20.cv3.conv.weight\n","freezing model.model.model.20.cv3.conv.bias\n","freezing model.model.model.20.m.0.cv1.conv.weight\n","freezing model.model.model.20.m.0.cv1.conv.bias\n","freezing model.model.model.20.m.0.cv2.conv.weight\n","freezing model.model.model.20.m.0.cv2.conv.bias\n","freezing model.model.model.21.conv.weight\n","freezing model.model.model.21.conv.bias\n","not freezing model.model.model.23.cv1.conv.weight\n","not freezing model.model.model.23.cv1.conv.bias\n","not freezing model.model.model.23.cv2.conv.weight\n","not freezing model.model.model.23.cv2.conv.bias\n","not freezing model.model.model.23.cv3.conv.weight\n","not freezing model.model.model.23.cv3.conv.bias\n","not freezing model.model.model.23.m.0.cv1.conv.weight\n","not freezing model.model.model.23.m.0.cv1.conv.bias\n","not freezing model.model.model.23.m.0.cv2.conv.weight\n","not freezing model.model.model.23.m.0.cv2.conv.bias\n","not freezing model.model.model.24.m.0.weight\n","not freezing model.model.model.24.m.0.bias\n","not freezing model.model.model.24.m.1.weight\n","not freezing model.model.model.24.m.1.bias\n","not freezing model.model.model.24.m.2.weight\n","not freezing model.model.model.24.m.2.bias\n"]}]},{"cell_type":"markdown","source":["# Dataset helper functions\n","extract data from xml, convert to YOLOv5 format\n"],"metadata":{"id":"T9GZ9A5XgJYF"}},{"cell_type":"code","source":["# Function to get the data from XML Annotation\n","\n","def extract_info_from_xml(xml_file):\n","    root = ET.parse(xml_file).getroot()\n","    \n","    # Initialise the info dict \n","    info_dict = {}\n","    info_dict['bboxes'] = []\n","\n","    # Parse the XML Tree\n","    for elem in root:\n","        # Get the file name \n","        if elem.tag == \"filename\":\n","            info_dict['filename'] = elem.text\n","            \n","        # Get the image size\n","        elif elem.tag == \"size\":\n","            image_size = []\n","            for subelem in elem:\n","                image_size.append(int(subelem.text))\n","            \n","            info_dict['image_size'] = tuple(image_size)\n","        \n","        # Get details of the bounding box \n","        elif elem.tag == \"object\":\n","            bbox = {}\n","            for subelem in elem:\n","                if subelem.tag == \"name\":\n","                    bbox[\"class\"] = subelem.text\n","                    \n","                elif subelem.tag == \"bndbox\":\n","                    for subsubelem in subelem:\n","                        bbox[subsubelem.tag] = int(subsubelem.text)            \n","            info_dict['bboxes'].append(bbox)\n","    \n","    return info_dict"],"metadata":{"id":"6j9pNu48PBO4","executionInfo":{"status":"ok","timestamp":1641544061527,"user_tz":-120,"elapsed":20,"user":{"displayName":"itamar ginsberg","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhgNNu4rKWDIJbuQ6EjlVLGe3VMZEHSAKyW4bG5qQ=s64","userId":"14768070087940992282"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["\n","# MANUAL EXTRACTION OF INFO FROM XML\n","#-----------------------------------\n","# tree = ET.parse('/content/drive/MyDrive/Colab Notebooks/046211_Deep_Learning/DL_project/data/Knife_detection/xmls/armas (1).xml')\n","# root = tree.getroot()\n","## name:\n","# print(root[6][0].text)\n","## coordinates: xmin\n","# print(root[6][4][0].text)\n","# ymin - [6][4][1]\n","# xmax - [6][4][2]\n","# yman - [6][4][3]\n","# for obj in root.iter('object'):\n","#   print(obj[0].text)\n","#   print(obj[4][0].text)\n","#   print(obj[4][1].text)\n","#   print(obj[4][2].text)\n","#   print(obj[4][3].text)\n","#-----------------------------------\n","# MANUAL EXTRACTION OF INFO FROM XML\n","\n","\n","\n","# USING THE ABOVE FUNCTION\n","#-------------------------\n","# example = extract_info_from_xml('/content/drive/MyDrive/Colab Notebooks/046211_Deep_Learning/DL_project/data/Knife_detection/xmls/armas (1).xml')\n","# print(example)"],"metadata":{"id":"YUJRQYfROLHG","executionInfo":{"status":"ok","timestamp":1641544061528,"user_tz":-120,"elapsed":20,"user":{"displayName":"itamar ginsberg","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhgNNu4rKWDIJbuQ6EjlVLGe3VMZEHSAKyW4bG5qQ=s64","userId":"14768070087940992282"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Dictionary that maps class names to IDs\n","class_name_to_id_mapping = {\"pistol\": 0,\n","                           \"knife\": 1}\n","\n","# Convert the info dict to the required yolo format and write it to disk\n","def convert_to_yolov5(info_dict):\n","    print_buffer = []\n","    \n","    # For each bounding box\n","    for b in info_dict[\"bboxes\"]:\n","        try:\n","            class_id = class_name_to_id_mapping[b[\"class\"]]\n","        except KeyError:\n","            print(\"Invalid Class. Must be one from \", class_name_to_id_mapping.keys())\n","        \n","        # Transform the bbox co-ordinates as per the format required by YOLO v5\n","        b_center_x = (b[\"xmin\"] + b[\"xmax\"]) / 2 \n","        b_center_y = (b[\"ymin\"] + b[\"ymax\"]) / 2\n","        b_width    = (b[\"xmax\"] - b[\"xmin\"])\n","        b_height   = (b[\"ymax\"] - b[\"ymin\"])\n","        \n","        # Normalise the co-ordinates by the dimensions of the image\n","        image_w, image_h, image_c = info_dict[\"image_size\"]  \n","        b_center_x /= image_w \n","        b_center_y /= image_h \n","        b_width    /= image_w \n","        b_height   /= image_h \n","        \n","        #Write the bbox details to the file \n","        print_buffer.append(\"{} {:.3f} {:.3f} {:.3f} {:.3f}\".format(class_id, b_center_x, b_center_y, b_width, b_height))\n","        \n","    # Name of the file which we have to save \n","    save_file_name = os.path.join(\"annotations2\", info_dict[\"filename\"].replace(\"JPG\", \"txt\"))\n","    \n","    # Save the annotation to disk\n","    print(\"\\n\".join(print_buffer), file= open(save_file_name, \"w\"))\n"],"metadata":{"id":"zCRqUCeDQUqx","executionInfo":{"status":"ok","timestamp":1641544061529,"user_tz":-120,"elapsed":21,"user":{"displayName":"itamar ginsberg","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhgNNu4rKWDIJbuQ6EjlVLGe3VMZEHSAKyW4bG5qQ=s64","userId":"14768070087940992282"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# convert all annotations with a loop - run once to create annotations\n","\n","# # Get the annotations\n","# annotations = [os.path.join('annotations', x) for x in os.listdir('./data/Knife_detection/annotations') if x[-3:] == \"xml\"]\n","# # annotations = [os.path.join(x) for x in os.listdir('./data/Pistol detection/xmls') if x[-3:] == \"xml\"]\n","# annotations.sort()\n","# print(annotations)\n","\n","# print(annotations)\n","# # Convert and save the annotations\n","\n","# for ann in tqdm(annotations):\n","#     print(ann)\n","#     info_dict = extract_info_from_xml(os.path.join('./data/Knife_detection', ann))\n","#     convert_to_yolov5(info_dict)\n","# annotations = [os.path.join('annotations', x) for x in os.listdir('annotations') if x[-3:] == \"txt\"]\n","# print(annotations)"],"metadata":{"id":"Fav6hZgvgBN9","executionInfo":{"status":"ok","timestamp":1641544061530,"user_tz":-120,"elapsed":21,"user":{"displayName":"itamar ginsberg","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhgNNu4rKWDIJbuQ6EjlVLGe3VMZEHSAKyW4bG5qQ=s64","userId":"14768070087940992282"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# THIS IS TEMP AND ONE-TIME\n","# ##########################\n","\n","# def add_numbers(filename):\n","#     with open(filename, 'r') as readfile:\n","#         data = readfile.readlines()\n","#     with open(filename, 'w') as writefile:\n","#         for i, line in enumerate(data):\n","#             writefile.write('%s %s' % (line, '.txt'))\n","\n","# filename = './annotations/armas (1)'\n","# add_numbers(filename)\n","\n","# for path, _, filenames in os.walk(folder):\n","#     for filename in filenames:\n","#         add_numbers(os.path.join(path, filename))\n","\n","\n","\n","\n","\n","### USE THIS:\n","#############\n","# from pathlib import Path\n","# for file in range(3,3001): \n","#   p = Path('./annotations/armas (' + str(file) + ')')\n","#   p.rename(p.with_suffix('.txt'))\n","#############\n","\n","\n","\n","\n","# THIS IS TEMP AND ONE-TIME\n","# ##########################"],"metadata":{"id":"jVcXT9O5fJsE","executionInfo":{"status":"ok","timestamp":1641544061531,"user_tz":-120,"elapsed":22,"user":{"displayName":"itamar ginsberg","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhgNNu4rKWDIJbuQ6EjlVLGe3VMZEHSAKyW4bG5qQ=s64","userId":"14768070087940992282"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["\n","# annotations = [os.path.join('annotation', x) for x in os.listdir('annotations') if x[-3:] == \"txt\"]\n","!pwd\n","annotations = os.listdir('./annotations')\n","print(annotations)\n","\n","class_id_to_name_mapping = dict(zip(class_name_to_id_mapping.values(), class_name_to_id_mapping.keys()))\n","\n","print(class_id_to_name_mapping)\n","\n","def plot_bounding_box(image, annotation_list):\n","    annotations = np.array(annotation_list)\n","    w, h = image.size\n","    \n","    plotted_image = ImageDraw.Draw(image)\n","\n","    transformed_annotations = np.copy(annotations)\n","    transformed_annotations[:,[1,3]] = annotations[:,[1,3]] * w\n","    transformed_annotations[:,[2,4]] = annotations[:,[2,4]] * h \n","    \n","    transformed_annotations[:,1] = transformed_annotations[:,1] - (transformed_annotations[:,3] / 2)\n","    transformed_annotations[:,2] = transformed_annotations[:,2] - (transformed_annotations[:,4] / 2)\n","    transformed_annotations[:,3] = transformed_annotations[:,1] + transformed_annotations[:,3]\n","    transformed_annotations[:,4] = transformed_annotations[:,2] + transformed_annotations[:,4]\n","    \n","    for ann in transformed_annotations:\n","        obj_cls, x0, y0, x1, y1 = ann\n","        plotted_image.rectangle(((x0,y0), (x1,y1)), width = 5, outline = 'red')\n","        \n","        plotted_image.text((x0, y0 - 10), class_id_to_name_mapping[(int(obj_cls))], fill = 'green')\n","    \n","    plt.imshow(np.array(image))\n","    plt.show()\n","\n","# Get any random annotation file \n","annotation_file = random.choice(annotations)\n","print(annotation_file)\n","annotation_file = os.path.join('./annotations', annotation_file)\n","print(annotation_file)\n","\n","with open(annotation_file, \"r\") as file:\n","    annotation_list = file.read().split(\"\\n\")[:-1]\n","    print(annotation_list)\n","    annotation_list = [x.split(\" \") for x in annotation_list]\n","    annotation_list = [[float(y) for y in x ] for x in annotation_list]\n","\n","#Get the corresponding image file\n","image_file = annotation_file.replace(\"annotations\", \"Weapons\").replace(\"txt\", \"jpg\")\n","print(image_file)\n","assert os.path.exists(image_file)\n","\n","#Load the image\n","image = Image.open(image_file)\n","\n","#Plot the Bounding Box\n","plot_bounding_box(image, annotation_list)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":335},"id":"ji_kKbDmYy34","executionInfo":{"status":"error","timestamp":1641544140318,"user_tz":-120,"elapsed":289,"user":{"displayName":"itamar ginsberg","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhgNNu4rKWDIJbuQ6EjlVLGe3VMZEHSAKyW4bG5qQ=s64","userId":"14768070087940992282"}},"outputId":"4e074564-03d8-424c-bc5b-88fc02157923"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/046211_Deep_Learning/DL_project\n","['train', 'test']\n","{0: 'pistol', 1: 'knife'}\n","train\n","./annotations/train\n"]},{"output_type":"error","ename":"IsADirectoryError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-3e03e3bd90d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotation_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotation_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mannotation_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotation_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: './annotations/train'"]}]},{"cell_type":"markdown","source":["# Data split and reorganize"],"metadata":{"id":"Sg24p8mFlnnJ"}},{"cell_type":"code","source":["# Read images and annotations\n","Weapons = [os.path.join('images', x) for x in os.listdir('images')]\n","annotations = [os.path.join('annotations', x) for x in os.listdir('annotations') if x[-3:] == \"txt\"]\n","\n","Weapons.sort()\n","annotations.sort()\n","\n","# Split the dataset into train-valid-test splits \n","train_images, test_images, train_annotations, test_annotations = train_test_split(Weapons, annotations, test_size = 0.2, random_state = 1)\n","# val_images, test_images, val_annotations, test_annotations = train_test_split(val_images, val_annotations, test_size = 0.5, random_state = 1)"],"metadata":{"id":"PVc-Rld5lmnJ","executionInfo":{"status":"aborted","timestamp":1641544075785,"user_tz":-120,"elapsed":8,"user":{"displayName":"itamar ginsberg","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhgNNu4rKWDIJbuQ6EjlVLGe3VMZEHSAKyW4bG5qQ=s64","userId":"14768070087940992282"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!mkdir images/train images/test annotations/train annotations/test"],"metadata":{"id":"Lq8to85bmQmi","executionInfo":{"status":"aborted","timestamp":1641544075790,"user_tz":-120,"elapsed":13,"user":{"displayName":"itamar ginsberg","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhgNNu4rKWDIJbuQ6EjlVLGe3VMZEHSAKyW4bG5qQ=s64","userId":"14768070087940992282"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Utility function to move images \n","def move_files_to_folder(list_of_files, destination_folder):\n","    for f in list_of_files:\n","        print(f)\n","        try:\n","            shutil.move(f, destination_folder)\n","        except:\n","            print(f)\n","            assert False\n","\n","# Move the splits into their folders\n","move_files_to_folder(train_images, 'images/train')\n","move_files_to_folder(train_annotations, 'annotations/train/')\n","move_files_to_folder(test_images, 'images/test/')\n","move_files_to_folder(test_annotations, 'annotations/test/')"],"metadata":{"id":"Rbi5sHUknzt6","executionInfo":{"status":"aborted","timestamp":1641544076241,"user_tz":-120,"elapsed":464,"user":{"displayName":"itamar ginsberg","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhgNNu4rKWDIJbuQ6EjlVLGe3VMZEHSAKyW4bG5qQ=s64","userId":"14768070087940992282"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Dataset class definition"],"metadata":{"id":"pMyovuq0gDoG"}},{"cell_type":"code","source":["class Weapon_Dataset(Dataset): # TODO - use xml package to read data from images and match with xml files\n","    \n","    def __init__(self, image_path,csv_file, Transform=None):\n","        # self.image_path = image_path\n","        # self.csv = pd.read_csv(csv_file) \n","        # self.transform = Transform\n","        \n","    def __len__(self): \n","      return len(self.csv)\n","    \n","    def __getitem__(self, idx): \n","      if torch.is_tensor(idx):\n","        idx = idx.tolist()\n","       \n","       # read image\n","       # read matching xml file\n","       \n","    #  image = Image.open(os.path.join(self.image_path, self.csv.iloc[idx,0]))\n","    #  label = self.csv.iloc[idx,1]\n","        #if self.image_path == '../input/cassava-leaf-disease-classification/train_images':\n","      return self.transform(image), label\n"],"metadata":{"id":"CFShpGEqNvAI","executionInfo":{"status":"aborted","timestamp":1641544076259,"user_tz":-120,"elapsed":482,"user":{"displayName":"itamar ginsberg","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhgNNu4rKWDIJbuQ6EjlVLGe3VMZEHSAKyW4bG5qQ=s64","userId":"14768070087940992282"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import Dataset, DataLoader\n","\n","\n","train_dataset = Cassava_Dataset(image_path,train_csv,basic_transform)\n","valid_set = Cassava_Dataset(image_path,test_csv_path,test_transform)\n","\n","\n","# train_dataset = torchvision.datasets.\n","# valid_dataset = torchvision.datasets.\n","# test_dataset = torchvision.datasets.\n","\n","batch_size = 128\n","\n","train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\n","valid_loader = torch.utils.data.DataLoader(valid_set,batch_size=batch_size,shuffle=True)\n","test_loader = torch.utils.data.DataLoader(test_set,batch_size=batch_size,shuffle=True)\n"],"metadata":{"id":"sPOcr1ifM9VE","executionInfo":{"status":"aborted","timestamp":1641544076260,"user_tz":-120,"elapsed":483,"user":{"displayName":"itamar ginsberg","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhgNNu4rKWDIJbuQ6EjlVLGe3VMZEHSAKyW4bG5qQ=s64","userId":"14768070087940992282"}}},"execution_count":null,"outputs":[]}]}